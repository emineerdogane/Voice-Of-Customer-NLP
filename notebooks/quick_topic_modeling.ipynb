{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29595631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "print(\"âœ… KÃ¼tÃ¼phaneler yÃ¼klendi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f422431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi yÃ¼kle\n",
    "df = pd.read_csv('../data/raw/music_reviews_20251224_031752.csv')\n",
    "print(f\"ğŸ“Š Toplam {len(df)} inceleme yÃ¼klendi\")\n",
    "print(f\"\\nKolonlar: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be273cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)  # URLs\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Special chars\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Extra spaces\n",
    "    return text\n",
    "\n",
    "# Ä°ncelemeleri temizle\n",
    "text_column = 'content' if 'content' in df.columns else 'review_text'\n",
    "df['cleaned_text'] = df[text_column].apply(clean_text)\n",
    "\n",
    "# Ã‡ok kÄ±sa incelemeleri Ã§Ä±kar\n",
    "df_clean = df[df['cleaned_text'].str.len() >= 20].copy()\n",
    "df_clean = df_clean.drop_duplicates(subset='cleaned_text').reset_index(drop=True)\n",
    "\n",
    "print(f\"ğŸ§¹ {len(df_clean)} temiz inceleme hazÄ±r\")\n",
    "df_clean[['cleaned_text', 'score']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da12bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERTopic model oluÅŸtur\n",
    "print(\"ğŸ¤– BERTopic modeli oluÅŸturuluyor...\")\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "vectorizer_model = CountVectorizer(stop_words='english', min_df=2, ngram_range=(1, 2))\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    min_topic_size=20,\n",
    "    nr_topics='auto',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"âœ… Model hazÄ±r!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c756e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic modeling yap\n",
    "print(\"ğŸ“Š Topic modeling baÅŸlÄ±yor... (Bu birkaÃ§ dakika sÃ¼rebilir)\")\n",
    "\n",
    "documents = df_clean['cleaned_text'].tolist()\n",
    "topics, probs = topic_model.fit_transform(documents)\n",
    "\n",
    "print(f\"\\nâœ… {len(set(topics))-1} topic bulundu! (-1 outliers hariÃ§)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11064e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic bilgilerini gÃ¶r\n",
    "topic_info = topic_model.get_topic_info()\n",
    "print(\"ğŸ“Š Topic DaÄŸÄ±lÄ±mÄ±:\")\n",
    "topic_info.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d3eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic'leri anlamlÄ± kategorilere Ã§evir\n",
    "def categorize_topic(topic_id, topic_words):\n",
    "    \"\"\"Topic kelimelerine gÃ¶re kategori ata\"\"\"\n",
    "    if topic_id == -1:\n",
    "        return \"Outliers\"\n",
    "    \n",
    "    words = ' '.join(topic_words)\n",
    "    \n",
    "    # Bug/Error keywords\n",
    "    if any(word in words for word in ['crash', 'bug', 'error', 'broken', 'fix', 'problem', 'issue']):\n",
    "        return \"ğŸ› Bugs & Errors\"\n",
    "    \n",
    "    # Login/Account keywords\n",
    "    if any(word in words for word in ['login', 'account', 'password', 'sign', 'authentication']):\n",
    "        return \"ğŸ” Login & Account Issues\"\n",
    "    \n",
    "    # UI/UX keywords\n",
    "    if any(word in words for word in ['interface', 'design', 'ui', 'ux', 'layout', 'menu']):\n",
    "        return \"ğŸ¨ UI/UX Issues\"\n",
    "    \n",
    "    # Feature Request keywords\n",
    "    if any(word in words for word in ['feature', 'add', 'want', 'need', 'wish', 'request']):\n",
    "        return \"ğŸ’¡ Feature Requests\"\n",
    "    \n",
    "    # Music/Audio keywords\n",
    "    if any(word in words for word in ['music', 'song', 'audio', 'sound', 'quality', 'playlist']):\n",
    "        return \"ğŸµ Music & Audio Quality\"\n",
    "    \n",
    "    # Subscription/Billing keywords\n",
    "    if any(word in words for word in ['subscription', 'premium', 'pay', 'billing', 'price', 'cost']):\n",
    "        return \"ğŸ’³ Subscription & Billing\"\n",
    "    \n",
    "    # Performance keywords\n",
    "    if any(word in words for word in ['slow', 'lag', 'performance', 'speed', 'loading']):\n",
    "        return \"âš¡ Performance Issues\"\n",
    "    \n",
    "    # Positive feedback\n",
    "    if any(word in words for word in ['love', 'great', 'amazing', 'best', 'perfect', 'excellent']):\n",
    "        return \"â­ Positive Feedback\"\n",
    "    \n",
    "    return f\"ğŸ“ Topic {topic_id}\"\n",
    "\n",
    "# Her topic iÃ§in kategori ata\n",
    "topic_categories = {}\n",
    "for idx, row in topic_info.iterrows():\n",
    "    topic_id = row['Topic']\n",
    "    # Topic kelimelerini al (ilk 10 kelime)\n",
    "    if topic_id != -1:\n",
    "        topic_words = [word for word, _ in topic_model.get_topic(topic_id)[:10]]\n",
    "    else:\n",
    "        topic_words = []\n",
    "    category = categorize_topic(topic_id, topic_words)\n",
    "    topic_categories[topic_id] = category\n",
    "\n",
    "print(\"âœ… Topic kategorileri oluÅŸturuldu!\")\n",
    "for tid, cat in list(topic_categories.items())[:10]:\n",
    "    print(f\"Topic {tid}: {cat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a16e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SonuÃ§larÄ± dataframe'e ekle\n",
    "df_clean['topic'] = topics\n",
    "df_clean['topic_category'] = df_clean['topic'].map(topic_categories)\n",
    "df_clean['topic_probability'] = [p.max() if len(p) > 0 else 0 for p in probs]\n",
    "\n",
    "print(\"\\nğŸ“Š Kategori DaÄŸÄ±lÄ±mÄ±:\")\n",
    "print(df_clean['topic_category'].value_counts())\n",
    "\n",
    "df_clean[['cleaned_text', 'score', 'topic_category', 'topic_probability']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aafb7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SonuÃ§larÄ± kaydet\n",
    "import os\n",
    "\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "output_path = '../data/processed/reviews_with_topics.csv'\n",
    "df_clean.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"âœ… SonuÃ§lar kaydedildi: {output_path}\")\n",
    "print(f\"\\nğŸ“ˆ Ã–zet:\")\n",
    "print(f\"  - Toplam iÅŸlenen inceleme: {len(df_clean):,}\")\n",
    "print(f\"  - Bulunan kategori sayÄ±sÄ±: {df_clean['topic_category'].nunique()}\")\n",
    "print(f\"  - En bÃ¼yÃ¼k kategori: {df_clean['topic_category'].value_counts().index[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b93cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her kategoriden Ã¶rnek incelemelere bak\n",
    "print(\"\\nğŸ” Her kategoriden Ã¶rnek incelemeler:\\n\")\n",
    "for category in df_clean['topic_category'].value_counts().head(5).index:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{category}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    samples = df_clean[df_clean['topic_category'] == category].head(3)\n",
    "    for idx, row in samples.iterrows():\n",
    "        print(f\"â­ {row['score']}/5: {row['cleaned_text'][:150]}...\")\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
